{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3tRl6ZSk8Oi"
   },
   "source": [
    "This notebook use for tunning model using embeddings file and language model embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz47D5H_R0UR"
   },
   "source": [
    "### Check GPU hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8kCH-Zfj2J_",
    "outputId": "86d483f6-7c82-4be8-8713-5c77b0966d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 11 07:50:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   52C    P8    16W / 170W |     15MiB / 12053MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1174      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1310      G   /usr/bin/gnome-shell                3MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiMnInVvlEjY"
   },
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBCZs6wgdV7E",
    "outputId": "f99d1941-a359-425e-aac3-514215ccd8bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries for system and debug\n",
    "import sys\n",
    "import pdb\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Class for converting sequences to tensors\n",
    "from seq2tensor import s2t\n",
    "\n",
    "# Libraries for neural network training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Input, Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import Add, Flatten, subtract, multiply, concatenate\n",
    "from tensorflow.keras.layers import MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Import accessory modules\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjxFKiABLDob"
   },
   "source": [
    "### Set CUDA environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wmbio/WORK/gitworking/PIPR'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjvCG7HCp0Af",
    "outputId": "1dc8ea23-ae15-4c5b-ac61-ebd1a32b1b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:50:22.339284: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-11 07:50:22.585017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10243 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "### Setting RAM GPU for training growth \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjvCG7HCp0Af",
    "outputId": "1dc8ea23-ae15-4c5b-ac61-ebd1a32b1b9e"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Optimisation Flags - Do not remove\n",
    "# ============================================\n",
    "\n",
    "# Disables caching (when set to 1) or enables caching (when set to 0) for just-in-time-compilation. When disabled,\n",
    "# no binary code is added to or retrieved from the cache.\n",
    "os.environ['CUDA_CACHE_DISABLE'] = '0' # orig is 0\n",
    "\n",
    "# When set to 1, forces the device driver to ignore any binary code embedded in an application \n",
    "# (see Application Compatibility) and to just-in-time compile embedded PTX code instead.\n",
    "# If a kernel does not have embedded PTX code, it will fail to load. This environment variable can be used to\n",
    "# validate that PTX code is embedded in an application and that its just-in-time compilation works as expected to guarantee application \n",
    "# forward compatibility with future architectures.\n",
    "os.environ['CUDA_FORCE_PTX_JIT'] = '1'# no orig\n",
    "\n",
    "\n",
    "os.environ['HOROVOD_GPU_ALLREDUCE'] = 'NCCL'\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT']='1'\n",
    "\n",
    "os.environ['TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT'] = '1'\n",
    "\n",
    "os.environ['TF_ADJUST_HUE_FUSED'] = '1'\n",
    "os.environ['TF_ADJUST_SATURATION_FUSED'] = '1'\n",
    "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "\n",
    "os.environ['TF_SYNC_ON_FINISH'] = '0'\n",
    "os.environ['TF_AUTOTUNE_THRESHOLD'] = '2'\n",
    "os.environ['TF_DISABLE_NVTX_RANGES'] = '1'\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjTWZj-Bzebi"
   },
   "source": [
    "### Define custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_pair(seq_tensor, class_labels, pair_index):\n",
    "    for index in pair_index:\n",
    "        yield {\"seq1\": seq_tensor[seq_index1[index]], \"seq2\": seq_tensor[seq_index2[index]]}, class_labels[index]\n",
    "\n",
    "def generator_pair_predict(seq_tensor, class_labels, pair_index):\n",
    "    for index in pair_index:\n",
    "        yield {\"seq1\": seq_tensor[seq_index1[index]], \"seq2\": seq_tensor[seq_index2[index]]}\n",
    "\n",
    "def input_preprocess(id2seq_file, ds_file, use_emb):\n",
    "    id2index = {}\n",
    "    seqs = []\n",
    "    index = 0\n",
    "    sid1_index = 0\n",
    "    sid2_index = 1\n",
    "    label_index = 2\n",
    "    \n",
    "    for line in open(id2seq_file):\n",
    "        line = line.strip().split('\\t')\n",
    "        id2index[line[0]] = index\n",
    "        seqs.append(line[1])\n",
    "        index += 1\n",
    "\n",
    "    seq_array = []\n",
    "    id2_aid = {}\n",
    "    sid = 0\n",
    "\n",
    "    seq2t = s2t(use_emb)\n",
    "    max_data = -1\n",
    "    limit_data = max_data > 0\n",
    "    raw_data = []\n",
    "    skip_head = True\n",
    "    x = None\n",
    "    count = 0\n",
    "    \n",
    "    # Create sequence array as a list of protein strings\n",
    "    for line in tqdm(open(ds_file)):\n",
    "        if skip_head:\n",
    "            skip_head = False\n",
    "            continue\n",
    "        line = line.rstrip('\\n').rstrip('\\r').split('\\t')\n",
    "        if id2index.get(line[sid1_index]) is None or id2index.get(line[sid2_index]) is None:\n",
    "            continue\n",
    "        if id2_aid.get(line[sid1_index]) is None:\n",
    "            id2_aid[line[sid1_index]] = sid\n",
    "            sid += 1\n",
    "            seq_array.append(seqs[id2index[line[sid1_index]]])\n",
    "        line[sid1_index] = id2_aid[line[sid1_index]]\n",
    "        if id2_aid.get(line[sid2_index]) is None:\n",
    "            id2_aid[line[sid2_index]] = sid\n",
    "            sid += 1\n",
    "            seq_array.append(seqs[id2index[line[sid2_index]]])\n",
    "        line[sid2_index] = id2_aid[line[sid2_index]]\n",
    "        raw_data.append(line)\n",
    "        if limit_data:\n",
    "            count += 1\n",
    "            if count >= max_data:\n",
    "                break\n",
    "\n",
    "    len_m_seq = np.array([len(line.split()) for line in seq_array])\n",
    "    avg_m_seq = int(np.average(len_m_seq)) + 1\n",
    "    max_m_seq = max(len_m_seq)\n",
    "    dim = seq2t.dim\n",
    "\n",
    "    # seq_tensor is tensor representation of dataset having shape of (number_of_sequences, padding_length, embedding_dim_of_aa)\n",
    "    # Random for distribution of class labels\n",
    "    seq_tensor = np.array([seq2t.embed_normalized(line, seq_size) for line in tqdm(seq_array)]).astype('float16')\n",
    "\n",
    "    # Extract index of 1st and 2nd sequences in pairs\n",
    "    seq_index1 = np.array([line[sid1_index] for line in tqdm(raw_data)])\n",
    "    seq_index2 = np.array([line[sid2_index] for line in tqdm(raw_data)])\n",
    "\n",
    "    # Assign labels for pairs of sequences\n",
    "    class_map = {'0': 1, '1': 0}\n",
    "    class_labels = np.zeros((len(raw_data), 2))\n",
    "    for i in range(len(raw_data)):\n",
    "        class_labels[i][class_map[raw_data[i][label_index]]] = 1\n",
    "        \n",
    "    return seq_tensor, seq_index1, seq_index2, class_labels, dim\n",
    "\n",
    "def leaky_relu(x, alpha = .3):\n",
    "    return tf.keras.backend.maximum(alpha*x, x)\n",
    "\n",
    "def build_model(hparams):\n",
    "    # Input of sequence tensor representations \n",
    "    seq_input1 = Input(shape=(seq_size, dim), name='seq1')\n",
    "    seq_input2 = Input(shape=(seq_size, dim), name='seq2')\n",
    "\n",
    "    # Define Conv1D and Bi-RNN (GRU/LSTM) use in architecture\n",
    "    l1=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r1=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l2=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r2=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l3=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r3=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l4=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r4=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l5=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r5=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l6=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    \n",
    "    # Siamese architecture\n",
    "\n",
    "    ### 1st sibling\n",
    "\n",
    "    # 1st Block RCNN \n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l1(seq_input1))\n",
    "    s1=concatenate([r1(s1), s1])\n",
    "\n",
    "    # 2nd Block RCNN\n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l2(s1))\n",
    "    s1=concatenate([r2(s1), s1])\n",
    "\n",
    "    # 3rd Block RCNN\n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l3(s1))\n",
    "    s1=concatenate([r3(s1), s1])\n",
    "\n",
    "    # 4th Block RCNN \n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l4(s1))\n",
    "    s1=concatenate([r4(s1), s1])\n",
    "\n",
    "    # 5th Block RCNN\n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l5(s1))\n",
    "    s1=concatenate([r5(s1), s1])\n",
    "    \n",
    "    # Last convolution\n",
    "    s1=l6(s1)\n",
    "    s1=GlobalAveragePooling1D()(s1)\n",
    "\n",
    "    ### 2nd sibling\n",
    "\n",
    "    # 1st block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l1(seq_input2))\n",
    "    s2=concatenate([r1(s2), s2])\n",
    "\n",
    "    # 2nd block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l2(s2))\n",
    "    s2=concatenate([r2(s2), s2])\n",
    "\n",
    "    # 3rd block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l3(s2))\n",
    "    s2=concatenate([r3(s2), s2])\n",
    "\n",
    "    # 4th block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l4(s2))\n",
    "    s2=concatenate([r4(s2), s2])\n",
    "\n",
    "    # 5th block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l5(s2))\n",
    "    s2=concatenate([r5(s2), s2])\n",
    "\n",
    "    # Last convolution\n",
    "    s2=l6(s2)\n",
    "    s2=GlobalAveragePooling1D()(s2)\n",
    "\n",
    "    ### Combine two siblings of siamese architecture\n",
    "    merge_text = multiply([s1, s2])\n",
    "    \n",
    "\n",
    "    #### MLP Part\n",
    "    # Set initializer\n",
    "    \n",
    "    # First dense\n",
    "    x = Dense(hparams[HP_FIRST_DENSE], activation=hparams[HP_ACTIVATION])(merge_text)\n",
    "    # x = tf.keras.layers.LeakyReLU(alpha=.3)(x)\n",
    "    x = Dropout(hparams[HP_DROPOUT])(x)\n",
    "\n",
    "    # Second dense\n",
    "    x = Dense(int((hparams[HP_CONV_HIDDEN_DIM]+7)/2), activation=hparams[HP_ACTIVATION])(x)\n",
    "    # x = tf.keras.layers.LeakyReLU(alpha=.3)(x)\n",
    "    x = Dropout(hparams[HP_DROPOUT])(x)\n",
    "\n",
    "    # Last softmax\n",
    "    main_output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Combine to form functional model\n",
    "    merge_model = Model(inputs=[seq_input1, seq_input2], outputs=[main_output])\n",
    "    return merge_model\n",
    "\n",
    "def seq_max(id2seq_file):\n",
    "    seqs = []\n",
    "    for line in open(id2seq_file):\n",
    "        line = line.strip().split('\\t')\n",
    "        seqs.append(len(line[1]))\n",
    "    \n",
    "    return max(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter set by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default hyperparameters\n",
    "CONV_HIDDEN_DIM = 50\n",
    "RNN_HIDDEN = 50\n",
    "N_EPOCHS = 50\n",
    "HIDDEN_DIM=50\n",
    "BATCH_SIZE = 32\n",
    "DTYPE='float16'\n",
    "LEARNING_RATE=.001\n",
    "EPSILON=1e-6\n",
    "adam = Adam(learning_rate=LEARNING_RATE, amsgrad=True, epsilon=EPSILON)\n",
    "MAX_DATASET_SIZE = 11187\n",
    "DATASET_SIZE = MAX_DATASET_SIZE\n",
    "KERNEL_SIZE = 3\n",
    "POOLING_KERNEL = 3\n",
    "seq_size = seq_max('data/wmbio_set/Train_set/human_custom_seq.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KgZZ2JvoBLw",
    "tags": []
   },
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "108156it [00:00, 767612.69it/s][A\n",
      "\n",
      "  0%|                                                                                               | 0/8992 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███████▎                                                                           | 794/8992 [00:00<00:01, 7938.85it/s]\u001b[A\n",
      " 18%|██████████████▌                                                                   | 1602/8992 [00:00<00:00, 8020.83it/s]\u001b[A\n",
      " 27%|██████████████████████                                                            | 2413/8992 [00:00<00:00, 8060.86it/s]\u001b[A\n",
      " 36%|█████████████████████████████▎                                                    | 3220/8992 [00:00<00:00, 8032.55it/s]\u001b[A\n",
      " 45%|████████████████████████████████████▋                                             | 4024/8992 [00:00<00:00, 7936.17it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████▉                                      | 4818/8992 [00:00<00:00, 7891.17it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████▏                              | 5608/8992 [00:00<00:00, 7869.40it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████▎                       | 6396/8992 [00:00<00:00, 7796.11it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 7195/8992 [00:00<00:00, 7852.06it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████         | 8007/8992 [00:01<00:00, 7932.04it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 8992/8992 [00:01<00:00, 7940.74it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 108155/108155 [00:00<00:00, 9475403.64it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 108155/108155 [00:00<00:00, 8786436.87it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# human custom\n",
    "seq_tensor, seq_index1, seq_index2, class_labels, dim = input_preprocess(id2seq_file='data/wmbio_set/Train_set/human_custom_seq.tsv',\n",
    "                                                                         ds_file='data/wmbio_set/Train_set/human_custom_ppi_pair.tsv', \n",
    "                                                                         use_emb = 'data/ac5_aph.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HyK_KJ6LUfR"
   },
   "source": [
    "### Search for optimal configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G34oBACWLqbw"
   },
   "source": [
    "### Define callbacks for monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VQdf1RAsYVcA"
   },
   "outputs": [],
   "source": [
    "### Learning rate schedule for optimization during training\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.4,\n",
    "    patience=4,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_lr=1e-5)\n",
    "\n",
    "# Schedule early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=6,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "final_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.4,\n",
    "    patience=4,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_lr=1e-5)\n",
    "\n",
    "final_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', \n",
    "    verbose=1,\n",
    "    patience=7,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLqkyCvrruF-"
   },
   "source": [
    "### Define performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Um2gRMVrZPi",
    "outputId": "96eda6e8-15af-44a5-caa7-c2adea7d4fbf"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      # tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2, name='mcc'),\n",
    "      tfa.metrics.F1Score(num_classes=2, threshold=0.5, name='f1-score'),\n",
    "      # keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkG4si5QSf15"
   },
   "source": [
    "### Summary of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0wMXJo9lqd6l",
    "outputId": "5ff95490-9d89-4b87-cc45-70b24481e945",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HP_EPSILON = hp.HParam('epsilon', hp.Discrete([1e-6]))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-3]))\n",
    "HP_FIRST_DENSE = hp.HParam('first_dense', hp.Discrete([100]))\n",
    "HP_KERNEL_SIZE = hp.HParam('kernel_size', hp.Discrete([3]))\n",
    "HP_POOLING_KERNEL = hp.HParam('pooling_kernel', hp.Discrete([3]))\n",
    "HP_CONV_HIDDEN_DIM = hp.HParam('conv_hidden_dim', hp.Discrete([50]))\n",
    "HP_RNN_HIDDEN_DIM = hp.HParam('rnn_hidden_dim', hp.Discrete([50]))\n",
    "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['leaky_relu']))\n",
    "HP_ACTIVATION_CONV = hp.HParam('activation_conv', hp.Discrete(['linear']))\n",
    "HP_REGULARIZER = hp.HParam('regularizer', hp.Discrete([0]))\n",
    "HP_CONV_PADDING = hp.HParam('conv_padding', hp.Discrete(['valid']))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0e-1]))\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([256]))\n",
    "HP_LEAKY_RELU = hp.HParam('leaky_relu', hp.Discrete([3e-1]))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "hparams = {\n",
    "  HP_EPSILON: EPSILON,\n",
    "  HP_LEARNING_RATE: LEARNING_RATE,\n",
    "  HP_FIRST_DENSE: 100,\n",
    "  HP_KERNEL_SIZE: 3,\n",
    "  HP_POOLING_KERNEL: 3,\n",
    "  HP_CONV_HIDDEN_DIM: 50,\n",
    "  HP_RNN_HIDDEN_DIM: 50,\n",
    "  HP_ACTIVATION: 'leaky_relu',\n",
    "  HP_ACTIVATION_CONV: 'relu',\n",
    "  HP_REGULARIZER: 0,\n",
    "  HP_CONV_PADDING: 'valid',\n",
    "  HP_DROPOUT: 3e-1,\n",
    "  HP_BATCH_SIZE: 256,\n",
    "  HP_LEAKY_RELU: 3e-1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-FOLD VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Training time =====================\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 09:00:31.716999: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-08 09:00:34.528182: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n",
      "2022-03-08 09:00:35.906688: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 249s 339ms/step - loss: 0.4507 - accuracy: 0.7717 - precision: 0.7717 - recall: 0.7717 - f1-score: 0.7370 - prc: 0.8671 - val_loss: 0.1655 - val_accuracy: 0.9376 - val_precision: 0.9376 - val_recall: 0.9376 - val_f1-score: 0.9348 - val_prc: 0.9808\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93764, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmbio/anaconda3/envs/pipr/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 226s 335ms/step - loss: 0.1308 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - f1-score: 0.9532 - prc: 0.9869 - val_loss: 0.1523 - val_accuracy: 0.9498 - val_precision: 0.9498 - val_recall: 0.9498 - val_f1-score: 0.9459 - val_prc: 0.9830\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.93764 to 0.94979, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 3/50\n",
      "675/675 [==============================] - 225s 334ms/step - loss: 0.0964 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - f1-score: 0.9654 - prc: 0.9921 - val_loss: 0.0950 - val_accuracy: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_f1-score: 0.9670 - val_prc: 0.9914\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.94979 to 0.96870, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 4/50\n",
      "675/675 [==============================] - 225s 333ms/step - loss: 0.0785 - accuracy: 0.9740 - precision: 0.9740 - recall: 0.9740 - f1-score: 0.9725 - prc: 0.9944 - val_loss: 0.0889 - val_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_f1-score: 0.9714 - val_prc: 0.9915\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96870 to 0.97286, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 5/50\n",
      "675/675 [==============================] - 227s 337ms/step - loss: 0.0664 - accuracy: 0.9782 - precision: 0.9782 - recall: 0.9782 - f1-score: 0.9770 - prc: 0.9956 - val_loss: 0.0951 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714 - val_f1-score: 0.9697 - val_prc: 0.9910\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.97286\n",
      "Epoch 6/50\n",
      "675/675 [==============================] - 228s 338ms/step - loss: 0.0590 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1-score: 0.9795 - prc: 0.9965 - val_loss: 0.0920 - val_accuracy: 0.9731 - val_precision: 0.9731 - val_recall: 0.9731 - val_f1-score: 0.9715 - val_prc: 0.9915\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.97286 to 0.97314, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 7/50\n",
      "675/675 [==============================] - 224s 332ms/step - loss: 0.0511 - accuracy: 0.9831 - precision: 0.9831 - recall: 0.9831 - f1-score: 0.9821 - prc: 0.9972 - val_loss: 0.1125 - val_accuracy: 0.9680 - val_precision: 0.9680 - val_recall: 0.9680 - val_f1-score: 0.9658 - val_prc: 0.9883\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.97314\n",
      "Epoch 8/50\n",
      "675/675 [==============================] - 229s 340ms/step - loss: 0.0455 - accuracy: 0.9849 - precision: 0.9849 - recall: 0.9849 - f1-score: 0.9840 - prc: 0.9977 - val_loss: 0.0954 - val_accuracy: 0.9754 - val_precision: 0.9754 - val_recall: 0.9754 - val_f1-score: 0.9740 - val_prc: 0.9909\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.97314 to 0.97541, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 9/50\n",
      "675/675 [==============================] - 226s 335ms/step - loss: 0.0412 - accuracy: 0.9861 - precision: 0.9861 - recall: 0.9861 - f1-score: 0.9853 - prc: 0.9981 - val_loss: 0.0970 - val_accuracy: 0.9756 - val_precision: 0.9756 - val_recall: 0.9756 - val_f1-score: 0.9741 - val_prc: 0.9907\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.97541 to 0.97564, saving model to save_model/1-fold_best_model.hdf5\n",
      "Epoch 10/50\n",
      "675/675 [==============================] - 224s 331ms/step - loss: 0.0364 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9877 - f1-score: 0.9869 - prc: 0.9984 - val_loss: 0.0901 - val_accuracy: 0.9780 - val_precision: 0.9780 - val_recall: 0.9780 - val_f1-score: 0.9767 - val_prc: 0.9920\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.97564 to 0.97804, saving model to save_model/1-fold_best_model.hdf5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "==================== Training time =====================\n",
      "Epoch 1/50\n",
      "675/675 [==============================] - 237s 338ms/step - loss: 0.4919 - accuracy: 0.7745 - precision: 0.7745 - recall: 0.7745 - f1-score: 0.7401 - prc: 0.8711 - val_loss: 0.1699 - val_accuracy: 0.9380 - val_precision: 0.9380 - val_recall: 0.9380 - val_f1-score: 0.9343 - val_prc: 0.9793\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93801, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmbio/anaconda3/envs/pipr/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 227s 336ms/step - loss: 0.1350 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - f1-score: 0.9519 - prc: 0.9861 - val_loss: 0.1085 - val_accuracy: 0.9634 - val_precision: 0.9634 - val_recall: 0.9634 - val_f1-score: 0.9610 - val_prc: 0.9900\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.93801 to 0.96339, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 3/50\n",
      "675/675 [==============================] - 225s 334ms/step - loss: 0.0990 - accuracy: 0.9666 - precision: 0.9666 - recall: 0.9666 - f1-score: 0.9647 - prc: 0.9918 - val_loss: 0.1267 - val_accuracy: 0.9573 - val_precision: 0.9573 - val_recall: 0.9573 - val_f1-score: 0.9539 - val_prc: 0.9880\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.96339\n",
      "Epoch 4/50\n",
      "675/675 [==============================] - 228s 338ms/step - loss: 0.0794 - accuracy: 0.9739 - precision: 0.9739 - recall: 0.9739 - f1-score: 0.9724 - prc: 0.9942 - val_loss: 0.1058 - val_accuracy: 0.9638 - val_precision: 0.9638 - val_recall: 0.9638 - val_f1-score: 0.9610 - val_prc: 0.9908\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96339 to 0.96380, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 5/50\n",
      "675/675 [==============================] - 233s 345ms/step - loss: 0.0684 - accuracy: 0.9781 - precision: 0.9781 - recall: 0.9781 - f1-score: 0.9769 - prc: 0.9954 - val_loss: 0.0848 - val_accuracy: 0.9735 - val_precision: 0.9735 - val_recall: 0.9735 - val_f1-score: 0.9717 - val_prc: 0.9927\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96380 to 0.97351, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 6/50\n",
      "675/675 [==============================] - 229s 340ms/step - loss: 0.0582 - accuracy: 0.9813 - precision: 0.9813 - recall: 0.9813 - f1-score: 0.9803 - prc: 0.9964 - val_loss: 0.0779 - val_accuracy: 0.9747 - val_precision: 0.9747 - val_recall: 0.9747 - val_f1-score: 0.9730 - val_prc: 0.9943\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.97351 to 0.97471, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 7/50\n",
      "675/675 [==============================] - 231s 342ms/step - loss: 0.0545 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - f1-score: 0.9816 - prc: 0.9969 - val_loss: 0.0750 - val_accuracy: 0.9755 - val_precision: 0.9755 - val_recall: 0.9755 - val_f1-score: 0.9738 - val_prc: 0.9943\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.97471 to 0.97550, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 8/50\n",
      "675/675 [==============================] - 231s 342ms/step - loss: 0.0487 - accuracy: 0.9847 - precision: 0.9847 - recall: 0.9847 - f1-score: 0.9838 - prc: 0.9972 - val_loss: 0.0759 - val_accuracy: 0.9771 - val_precision: 0.9771 - val_recall: 0.9771 - val_f1-score: 0.9756 - val_prc: 0.9936\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.97550 to 0.97707, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 9/50\n",
      "675/675 [==============================] - 222s 330ms/step - loss: 0.0440 - accuracy: 0.9858 - precision: 0.9858 - recall: 0.9858 - f1-score: 0.9850 - prc: 0.9978 - val_loss: 0.0770 - val_accuracy: 0.9776 - val_precision: 0.9776 - val_recall: 0.9776 - val_f1-score: 0.9761 - val_prc: 0.9930\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.97707 to 0.97762, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 10/50\n",
      "675/675 [==============================] - 225s 333ms/step - loss: 0.0407 - accuracy: 0.9866 - precision: 0.9866 - recall: 0.9866 - f1-score: 0.9858 - prc: 0.9981 - val_loss: 0.0783 - val_accuracy: 0.9778 - val_precision: 0.9778 - val_recall: 0.9778 - val_f1-score: 0.9764 - val_prc: 0.9932\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.97762 to 0.97776, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 11/50\n",
      "675/675 [==============================] - 225s 333ms/step - loss: 0.0380 - accuracy: 0.9874 - precision: 0.9874 - recall: 0.9874 - f1-score: 0.9867 - prc: 0.9983 - val_loss: 0.0847 - val_accuracy: 0.9783 - val_precision: 0.9783 - val_recall: 0.9783 - val_f1-score: 0.9769 - val_prc: 0.9916\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.97776 to 0.97827, saving model to save_model/2-fold_best_model.hdf5\n",
      "Epoch 12/50\n",
      "675/675 [==============================] - 232s 343ms/step - loss: 0.0372 - accuracy: 0.9873 - precision: 0.9873 - recall: 0.9873 - f1-score: 0.9866 - prc: 0.9984 - val_loss: 0.0828 - val_accuracy: 0.9764 - val_precision: 0.9764 - val_recall: 0.9764 - val_f1-score: 0.9748 - val_prc: 0.9925\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97827\n",
      "Epoch 13/50\n",
      "675/675 [==============================] - 229s 339ms/step - loss: 0.0322 - accuracy: 0.9892 - precision: 0.9892 - recall: 0.9892 - f1-score: 0.9886 - prc: 0.9987 - val_loss: 0.1001 - val_accuracy: 0.9747 - val_precision: 0.9747 - val_recall: 0.9747 - val_f1-score: 0.9732 - val_prc: 0.9908\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97827\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "==================== Training time =====================\n",
      "Epoch 1/50\n",
      "675/675 [==============================] - 254s 348ms/step - loss: 0.4892 - accuracy: 0.7752 - precision: 0.7752 - recall: 0.7752 - f1-score: 0.7446 - prc: 0.8719 - val_loss: 0.1783 - val_accuracy: 0.9419 - val_precision: 0.9419 - val_recall: 0.9419 - val_f1-score: 0.9380 - val_prc: 0.9796\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.94189, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmbio/anaconda3/envs/pipr/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 230s 341ms/step - loss: 0.1437 - accuracy: 0.9511 - precision: 0.9511 - recall: 0.9511 - f1-score: 0.9484 - prc: 0.9846 - val_loss: 0.1103 - val_accuracy: 0.9620 - val_precision: 0.9620 - val_recall: 0.9620 - val_f1-score: 0.9599 - val_prc: 0.9901\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.94189 to 0.96205, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 3/50\n",
      "675/675 [==============================] - 225s 334ms/step - loss: 0.1031 - accuracy: 0.9648 - precision: 0.9648 - recall: 0.9648 - f1-score: 0.9628 - prc: 0.9914 - val_loss: 0.1006 - val_accuracy: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_f1-score: 0.9647 - val_prc: 0.9911\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.96205 to 0.96671, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 4/50\n",
      "675/675 [==============================] - 229s 339ms/step - loss: 0.0830 - accuracy: 0.9720 - precision: 0.9720 - recall: 0.9720 - f1-score: 0.9704 - prc: 0.9940 - val_loss: 0.0932 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_recall: 0.9698 - val_f1-score: 0.9678 - val_prc: 0.9919\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96671 to 0.96981, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 5/50\n",
      "675/675 [==============================] - 229s 339ms/step - loss: 0.0695 - accuracy: 0.9765 - precision: 0.9765 - recall: 0.9765 - f1-score: 0.9752 - prc: 0.9955 - val_loss: 0.0842 - val_accuracy: 0.9739 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1-score: 0.9723 - val_prc: 0.9932\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.96981 to 0.97388, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 6/50\n",
      "675/675 [==============================] - 228s 338ms/step - loss: 0.0599 - accuracy: 0.9802 - precision: 0.9802 - recall: 0.9802 - f1-score: 0.9790 - prc: 0.9963 - val_loss: 0.0811 - val_accuracy: 0.9765 - val_precision: 0.9765 - val_recall: 0.9765 - val_f1-score: 0.9751 - val_prc: 0.9930\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.97388 to 0.97647, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 7/50\n",
      "675/675 [==============================] - 228s 338ms/step - loss: 0.0538 - accuracy: 0.9821 - precision: 0.9821 - recall: 0.9821 - f1-score: 0.9810 - prc: 0.9970 - val_loss: 0.0744 - val_accuracy: 0.9776 - val_precision: 0.9776 - val_recall: 0.9776 - val_f1-score: 0.9763 - val_prc: 0.9940\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.97647 to 0.97762, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 8/50\n",
      "675/675 [==============================] - 226s 335ms/step - loss: 0.0467 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - f1-score: 0.9837 - prc: 0.9976 - val_loss: 0.0782 - val_accuracy: 0.9761 - val_precision: 0.9761 - val_recall: 0.9761 - val_f1-score: 0.9747 - val_prc: 0.9932\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.97762\n",
      "Epoch 9/50\n",
      "675/675 [==============================] - 226s 334ms/step - loss: 0.0430 - accuracy: 0.9857 - precision: 0.9857 - recall: 0.9857 - f1-score: 0.9849 - prc: 0.9978 - val_loss: 0.0857 - val_accuracy: 0.9762 - val_precision: 0.9762 - val_recall: 0.9762 - val_f1-score: 0.9748 - val_prc: 0.9921\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.97762\n",
      "Epoch 10/50\n",
      "675/675 [==============================] - 229s 340ms/step - loss: 0.0388 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - f1-score: 0.9863 - prc: 0.9982 - val_loss: 0.0795 - val_accuracy: 0.9776 - val_precision: 0.9776 - val_recall: 0.9776 - val_f1-score: 0.9762 - val_prc: 0.9928\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.97762\n",
      "Epoch 11/50\n",
      "675/675 [==============================] - 232s 344ms/step - loss: 0.0352 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - f1-score: 0.9874 - prc: 0.9985 - val_loss: 0.0776 - val_accuracy: 0.9801 - val_precision: 0.9801 - val_recall: 0.9801 - val_f1-score: 0.9789 - val_prc: 0.9930\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.97762 to 0.98007, saving model to save_model/3-fold_best_model.hdf5\n",
      "Epoch 12/50\n",
      "675/675 [==============================] - 224s 332ms/step - loss: 0.0323 - accuracy: 0.9889 - precision: 0.9889 - recall: 0.9889 - f1-score: 0.9883 - prc: 0.9987 - val_loss: 0.0907 - val_accuracy: 0.9776 - val_precision: 0.9776 - val_recall: 0.9776 - val_f1-score: 0.9762 - val_prc: 0.9909\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98007\n",
      "Epoch 13/50\n",
      "675/675 [==============================] - 228s 338ms/step - loss: 0.0317 - accuracy: 0.9889 - precision: 0.9889 - recall: 0.9889 - f1-score: 0.9883 - prc: 0.9988 - val_loss: 0.0966 - val_accuracy: 0.9802 - val_precision: 0.9802 - val_recall: 0.9802 - val_f1-score: 0.9790 - val_prc: 0.9908\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.98007 to 0.98017, saving model to save_model/3-fold_best_model.hdf5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "==================== Training time =====================\n",
      "Epoch 1/50\n",
      "675/675 [==============================] - 250s 342ms/step - loss: 0.4873 - accuracy: 0.7758 - precision: 0.7758 - recall: 0.7758 - f1-score: 0.7406 - prc: 0.8725 - val_loss: 0.1951 - val_accuracy: 0.9288 - val_precision: 0.9288 - val_recall: 0.9288 - val_f1-score: 0.9260 - val_prc: 0.9731\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92881, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmbio/anaconda3/envs/pipr/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 228s 338ms/step - loss: 0.1358 - accuracy: 0.9535 - precision: 0.9535 - recall: 0.9535 - f1-score: 0.9508 - prc: 0.9861 - val_loss: 0.1294 - val_accuracy: 0.9565 - val_precision: 0.9565 - val_recall: 0.9565 - val_f1-score: 0.9543 - val_prc: 0.9864\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.92881 to 0.95645, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 3/50\n",
      "675/675 [==============================] - 229s 339ms/step - loss: 0.0947 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - f1-score: 0.9661 - prc: 0.9927 - val_loss: 0.1096 - val_accuracy: 0.9644 - val_precision: 0.9644 - val_recall: 0.9644 - val_f1-score: 0.9624 - val_prc: 0.9901\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.95645 to 0.96445, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 4/50\n",
      "675/675 [==============================] - 225s 333ms/step - loss: 0.0770 - accuracy: 0.9742 - precision: 0.9742 - recall: 0.9742 - f1-score: 0.9727 - prc: 0.9948 - val_loss: 0.1143 - val_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_f1-score: 0.9681 - val_prc: 0.9880\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.96445 to 0.96963, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 5/50\n",
      "675/675 [==============================] - 227s 336ms/step - loss: 0.0628 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - f1-score: 0.9783 - prc: 0.9961 - val_loss: 0.1036 - val_accuracy: 0.9686 - val_precision: 0.9686 - val_recall: 0.9686 - val_f1-score: 0.9671 - val_prc: 0.9897\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.96963\n",
      "Epoch 6/50\n",
      "675/675 [==============================] - 227s 336ms/step - loss: 0.0526 - accuracy: 0.9829 - precision: 0.9829 - recall: 0.9829 - f1-score: 0.9819 - prc: 0.9970 - val_loss: 0.1126 - val_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_f1-score: 0.9679 - val_prc: 0.9883\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.96963\n",
      "Epoch 7/50\n",
      "675/675 [==============================] - 228s 337ms/step - loss: 0.0493 - accuracy: 0.9840 - precision: 0.9840 - recall: 0.9840 - f1-score: 0.9831 - prc: 0.9974 - val_loss: 0.0951 - val_accuracy: 0.9750 - val_precision: 0.9750 - val_recall: 0.9750 - val_f1-score: 0.9736 - val_prc: 0.9906\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.96963 to 0.97499, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 8/50\n",
      "675/675 [==============================] - 228s 339ms/step - loss: 0.0421 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - f1-score: 0.9854 - prc: 0.9979 - val_loss: 0.1025 - val_accuracy: 0.9738 - val_precision: 0.9738 - val_recall: 0.9738 - val_f1-score: 0.9722 - val_prc: 0.9898\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.97499\n",
      "Epoch 9/50\n",
      "675/675 [==============================] - 228s 337ms/step - loss: 0.0397 - accuracy: 0.9870 - precision: 0.9870 - recall: 0.9870 - f1-score: 0.9862 - prc: 0.9981 - val_loss: 0.1036 - val_accuracy: 0.9767 - val_precision: 0.9767 - val_recall: 0.9767 - val_f1-score: 0.9755 - val_prc: 0.9893\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.97499 to 0.97675, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 10/50\n",
      "675/675 [==============================] - 227s 337ms/step - loss: 0.0356 - accuracy: 0.9884 - precision: 0.9884 - recall: 0.9884 - f1-score: 0.9877 - prc: 0.9984 - val_loss: 0.1062 - val_accuracy: 0.9739 - val_precision: 0.9739 - val_recall: 0.9739 - val_f1-score: 0.9724 - val_prc: 0.9894\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.97675\n",
      "Epoch 11/50\n",
      "675/675 [==============================] - 229s 339ms/step - loss: 0.0323 - accuracy: 0.9893 - precision: 0.9893 - recall: 0.9893 - f1-score: 0.9886 - prc: 0.9987 - val_loss: 0.1043 - val_accuracy: 0.9776 - val_precision: 0.9776 - val_recall: 0.9776 - val_f1-score: 0.9765 - val_prc: 0.9890\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.97675 to 0.97762, saving model to save_model/4-fold_best_model.hdf5\n",
      "Epoch 12/50\n",
      "675/675 [==============================] - 226s 335ms/step - loss: 0.0309 - accuracy: 0.9893 - precision: 0.9893 - recall: 0.9893 - f1-score: 0.9887 - prc: 0.9988 - val_loss: 0.1243 - val_accuracy: 0.9771 - val_precision: 0.9771 - val_recall: 0.9771 - val_f1-score: 0.9758 - val_prc: 0.9875\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97762\n",
      "Epoch 13/50\n",
      "675/675 [==============================] - 226s 335ms/step - loss: 0.0285 - accuracy: 0.9901 - precision: 0.9901 - recall: 0.9901 - f1-score: 0.9896 - prc: 0.9990 - val_loss: 0.1069 - val_accuracy: 0.9773 - val_precision: 0.9773 - val_recall: 0.9773 - val_f1-score: 0.9760 - val_prc: 0.9901\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97762\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "==================== Training time =====================\n",
      "Epoch 1/50\n",
      "590/675 [=========================>....] - ETA: 26s - loss: 0.5668 - accuracy: 0.7326 - precision: 0.7326 - recall: 0.7326 - f1-score: 0.6796 - prc: 0.8240"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cnt = 0\n",
    "\n",
    "# save models\n",
    "SAVE_MODEL = 'save_model_baseline/'\n",
    "Path(SAVE_MODEL).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# log\n",
    "with tf.summary.create_file_writer(SAVE_MODEL + 'logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_EPSILON,HP_LEARNING_RATE,HP_FIRST_DENSE, HP_KERNEL_SIZE, HP_POOLING_KERNEL, HP_CONV_HIDDEN_DIM, HP_RNN_HIDDEN_DIM, HP_ACTIVATION, HP_ACTIVATION_CONV, HP_REGULARIZER, HP_CONV_PADDING, HP_DROPOUT, HP_BATCH_SIZE, HP_LEAKY_RELU],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n",
    "\n",
    "\n",
    "for train, test in kf.split(class_labels):\n",
    "    cnt+=1\n",
    "    merge_model = None\n",
    "    merge_model = build_model(hparams)  \n",
    "    tf.keras.utils.plot_model(merge_model, to_file=SAVE_MODEL + 'model.png', show_shapes=True)\n",
    "\n",
    "\n",
    "    merge_model.compile(optimizer=Adam(learning_rate=hparams[HP_LEARNING_RATE], amsgrad=True, epsilon=hparams[HP_EPSILON]), \n",
    "                      loss='categorical_crossentropy', metrics=METRICS)\n",
    "    \n",
    "    # Create train\n",
    "    # from generator\n",
    "    train_dataset = tf.data.Dataset.from_generator(generator_pair, \n",
    "                                                   args=[seq_tensor, class_labels, train], \n",
    "                                                   output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), \n",
    "                                                   output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
    "    train_dataset = train_dataset.shuffle(1024).repeat(N_EPOCHS).batch(hparams[HP_BATCH_SIZE])\n",
    "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Create test\n",
    "    test_dataset = tf.data.Dataset.from_generator(generator_pair, args=[seq_tensor, class_labels, test], \n",
    "                                                  output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), \n",
    "                                                  output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
    "    test_dataset = test_dataset.batch(hparams[HP_BATCH_SIZE])\n",
    "    \n",
    "    # Save the best model base on val_accuracy\n",
    "    checkpoint = ModelCheckpoint(filepath=SAVE_MODEL + str(cnt)+'-fold_best_model.hdf5', \n",
    "                                 monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "    \n",
    "    # Fit model\n",
    "    print(f'==================== Training time =====================')\n",
    "    history_model = merge_model.fit(train_dataset, \n",
    "                                    epochs=N_EPOCHS, \n",
    "                                    steps_per_epoch=len(train) // 128, \n",
    "                                    validation_data=test_dataset,\n",
    "                                    callbacks=[checkpoint, reduce_lr, early_stopping,                                               \n",
    "                                              tf.keras.callbacks.CSVLogger(SAVE_MODEL + 'history.csv')])\n",
    "    # file rename\n",
    "    shutil.move(SAVE_MODEL + 'history.csv', SAVE_MODEL + str(cnt) + '-fold_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4b9czlGzdOR4",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3c95c5fd-679e-42cb-abef-10769257e1bf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "70/70 [==============================] - 36s 253ms/step - loss: 0.6576 - accuracy: 0.7985 - precision: 0.7985 - recall: 0.7985 - f1-score: 0.7616 - prc: 0.9036\n",
      "Epoch 2/30\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.6475 - accuracy: 0.6388 - precision: 0.6388 - recall: 0.6388 - f1-score: 0.5160 - prc: 0.6422\n",
      "Epoch 3/30\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.6494 - accuracy: 0.6352 - precision: 0.6352 - recall: 0.6352 - f1-score: 0.5170 - prc: 0.6397\n",
      "Epoch 4/30\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.6423 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - f1-score: 0.5302 - prc: 0.6532\n",
      "Epoch 5/30\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.6278 - accuracy: 0.6585 - precision: 0.6585 - recall: 0.6585 - f1-score: 0.5753 - prc: 0.6835\n",
      "Epoch 6/30\n",
      "70/70 [==============================] - 18s 252ms/step - loss: 0.5479 - accuracy: 0.7185 - precision: 0.7185 - recall: 0.7185 - f1-score: 0.6858 - prc: 0.7905\n",
      "Epoch 7/30\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.4117 - accuracy: 0.8128 - precision: 0.8128 - recall: 0.8128 - f1-score: 0.8029 - prc: 0.8932\n",
      "Epoch 8/30\n",
      "70/70 [==============================] - 17s 249ms/step - loss: 0.3286 - accuracy: 0.8627 - precision: 0.8627 - recall: 0.8627 - f1-score: 0.8561 - prc: 0.9333\n",
      "Epoch 9/30\n",
      "70/70 [==============================] - 17s 250ms/step - loss: 0.2370 - accuracy: 0.9095 - precision: 0.9095 - recall: 0.9095 - f1-score: 0.9050 - prc: 0.9639\n",
      "Epoch 10/30\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.1992 - accuracy: 0.9294 - precision: 0.9294 - recall: 0.9294 - f1-score: 0.9259 - prc: 0.9734\n",
      "Epoch 11/30\n",
      "70/70 [==============================] - 18s 253ms/step - loss: 0.1748 - accuracy: 0.9383 - precision: 0.9383 - recall: 0.9383 - f1-score: 0.9351 - prc: 0.9788\n",
      "Epoch 12/30\n",
      "70/70 [==============================] - 17s 250ms/step - loss: 0.1544 - accuracy: 0.9468 - precision: 0.9468 - recall: 0.9468 - f1-score: 0.9438 - prc: 0.9832\n",
      "Epoch 13/30\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.1673 - accuracy: 0.9428 - precision: 0.9428 - recall: 0.9428 - f1-score: 0.9396 - prc: 0.9803\n",
      "Epoch 14/30\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.1417 - accuracy: 0.9519 - precision: 0.9519 - recall: 0.9519 - f1-score: 0.9491 - prc: 0.9855\n",
      "Epoch 15/30\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.1282 - accuracy: 0.9575 - precision: 0.9575 - recall: 0.9575 - f1-score: 0.9552 - prc: 0.9877\n",
      "Epoch 16/30\n",
      "70/70 [==============================] - 17s 243ms/step - loss: 0.1272 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - f1-score: 0.9541 - prc: 0.9878\n",
      "Epoch 17/30\n",
      "70/70 [==============================] - 17s 240ms/step - loss: 0.1182 - accuracy: 0.9599 - precision: 0.9599 - recall: 0.9599 - f1-score: 0.9577 - prc: 0.9891\n",
      "Epoch 18/30\n",
      "70/70 [==============================] - 18s 251ms/step - loss: 0.1125 - accuracy: 0.9607 - precision: 0.9607 - recall: 0.9607 - f1-score: 0.9584 - prc: 0.9901\n",
      "Epoch 19/30\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.1238 - accuracy: 0.9578 - precision: 0.9578 - recall: 0.9578 - f1-score: 0.9553 - prc: 0.9886\n",
      "Epoch 20/30\n",
      "70/70 [==============================] - 18s 251ms/step - loss: 0.1094 - accuracy: 0.9629 - precision: 0.9629 - recall: 0.9629 - f1-score: 0.9608 - prc: 0.9905\n",
      "Epoch 21/30\n",
      "70/70 [==============================] - 17s 249ms/step - loss: 0.1017 - accuracy: 0.9647 - precision: 0.9647 - recall: 0.9647 - f1-score: 0.9628 - prc: 0.9919\n",
      "Epoch 22/30\n",
      "70/70 [==============================] - 17s 247ms/step - loss: 0.1107 - accuracy: 0.9636 - precision: 0.9636 - recall: 0.9636 - f1-score: 0.9615 - prc: 0.9900\n",
      "Epoch 23/30\n",
      "70/70 [==============================] - 17s 241ms/step - loss: 0.1015 - accuracy: 0.9661 - precision: 0.9661 - recall: 0.9661 - f1-score: 0.9642 - prc: 0.9919\n",
      "Epoch 24/30\n",
      "70/70 [==============================] - 17s 242ms/step - loss: 0.0914 - accuracy: 0.9707 - precision: 0.9707 - recall: 0.9707 - f1-score: 0.9689 - prc: 0.9925\n",
      "Epoch 25/30\n",
      "70/70 [==============================] - 18s 251ms/step - loss: 0.0971 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - f1-score: 0.9662 - prc: 0.9921\n",
      "Epoch 26/30\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0956 - accuracy: 0.9662 - precision: 0.9662 - recall: 0.9662 - f1-score: 0.9642 - prc: 0.9926\n",
      "Epoch 27/30\n",
      "70/70 [==============================] - 18s 255ms/step - loss: 0.0844 - accuracy: 0.9719 - precision: 0.9719 - recall: 0.9719 - f1-score: 0.9704 - prc: 0.9938\n",
      "Epoch 28/30\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0900 - accuracy: 0.9693 - precision: 0.9693 - recall: 0.9693 - f1-score: 0.9676 - prc: 0.9931\n",
      "Epoch 29/30\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0861 - accuracy: 0.9713 - precision: 0.9713 - recall: 0.9713 - f1-score: 0.9696 - prc: 0.9938\n",
      "Epoch 30/30\n",
      "70/70 [==============================] - 18s 252ms/step - loss: 0.0802 - accuracy: 0.9741 - precision: 0.9741 - recall: 0.9741 - f1-score: 0.9725 - prc: 0.9939\n"
     ]
    }
   ],
   "source": [
    "merge_model = None\n",
    "merge_model = build_model(hparams)  \n",
    "\n",
    "# ADAM\n",
    "merge_model.compile(optimizer=Adam(learning_rate=hparams[HP_LEARNING_RATE], \n",
    "                                   amsgrad=True, epsilon=hparams[HP_EPSILON]), \n",
    "                    loss='categorical_crossentropy', metrics=METRICS)\n",
    "\n",
    "# Create train\n",
    "train_dataset = tf.data.Dataset.from_generator(generator_pair, \n",
    "                                               args=[seq_tensor, class_labels, np.arange(len(class_labels))], \n",
    "                                               output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), \n",
    "                                               output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
    "train_dataset = train_dataset.shuffle(1024).repeat(N_EPOCHS).batch(hparams[HP_BATCH_SIZE])\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Fit model\n",
    "history = merge_model.fit(train_dataset, \n",
    "                steps_per_epoch=len(seq_tensor) // 128, \n",
    "                epochs=30,\n",
    "                callbacks=[final_reduce_lr, final_early_stopping])\n",
    "\n",
    "# model save\n",
    "SAVE_MODEL = 'final_model/'\n",
    "Path(SAVE_MODEL).mkdir(parents=True, exist_ok=True)\n",
    "merge_model.save(SAVE_MODEL + 'PIPR_baseline_final.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluation-Benchmark-dataset-baseline-PIPR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pipr",
   "language": "python",
   "name": "pipr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
