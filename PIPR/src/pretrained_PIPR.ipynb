{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3tRl6ZSk8Oi"
   },
   "source": [
    "This notebook use for tunning model using embeddings file and language model embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz47D5H_R0UR"
   },
   "source": [
    "### Check GPU hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8kCH-Zfj2J_",
    "outputId": "86d483f6-7c82-4be8-8713-5c77b0966d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 14 08:45:10 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   51C    P8    15W / 170W |     15MiB / 12053MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1174      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1310      G   /usr/bin/gnome-shell                3MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiMnInVvlEjY"
   },
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBCZs6wgdV7E",
    "outputId": "f99d1941-a359-425e-aac3-514215ccd8bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries for system and debug\n",
    "import sys\n",
    "import pdb\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Libraries for neural network training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Input, Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import Add, Flatten, subtract, multiply, concatenate\n",
    "from tensorflow.keras.layers import MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Bio import SeqIO\n",
    "from bio_embeddings.embed import BeplerEmbedder,ProtTransT5XLU50Embedder,ESM1bEmbedder\n",
    "\n",
    "# Import accessory modules\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjxFKiABLDob"
   },
   "source": [
    "### Set CUDA environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjvCG7HCp0Af",
    "outputId": "1dc8ea23-ae15-4c5b-ac61-ebd1a32b1b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 08:45:19.735712: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-14 08:45:22.462892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8839 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "### Setting RAM GPU for training growth \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjTWZj-Bzebi"
   },
   "source": [
    "### Define custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_pair(seq_tensor, class_labels, pair_index):\n",
    "    for index in pair_index:\n",
    "        yield {\"seq1\": seq_tensor[seq_index1[index]], \"seq2\": seq_tensor[seq_index2[index]]}, class_labels[index]\n",
    "\n",
    "def generator_pair_predict(seq_tensor, pair_index):\n",
    "    for index in pair_index:\n",
    "        yield {\"seq1\": seq_tensor[seq_index1[index]], \"seq2\": seq_tensor[seq_index2[index]]}\n",
    "\n",
    "def seq_max(id2seq_file):\n",
    "    seqs = []\n",
    "    for line in open(id2seq_file):\n",
    "        line = line.strip().split('\\t')\n",
    "        seqs.append(len(line[1]))\n",
    "    \n",
    "    return max(seqs)\n",
    "        \n",
    "def preprocess_embed(id2seq_file, ds_file, e_type):\n",
    "    id2index = {}\n",
    "    seqs = []\n",
    "    index = 0\n",
    "    sid1_index = 0\n",
    "    sid2_index = 1\n",
    "    label_index = 2\n",
    "    \n",
    "    for line in open(id2seq_file):\n",
    "        line = line.strip().split('\\t')\n",
    "        id2index[line[0]] = index\n",
    "        seqs.append(line[1])\n",
    "        index += 1\n",
    "\n",
    "    seq_array = []\n",
    "    id2_aid = {}\n",
    "    sid = 0\n",
    "\n",
    "    max_data = -1\n",
    "    limit_data = max_data > 0\n",
    "    raw_data = []\n",
    "    x = None\n",
    "    count = 0\n",
    "    \n",
    "    # Create sequence array as a list of protein strings\n",
    "    for line in tqdm(open(ds_file)):\n",
    "        line = line.rstrip('\\n').rstrip('\\r').split('\\t')\n",
    "        if id2index.get(line[sid1_index]) is None or id2index.get(line[sid2_index]) is None:\n",
    "            continue\n",
    "        if id2_aid.get(line[sid1_index]) is None:\n",
    "            id2_aid[line[sid1_index]] = sid\n",
    "            sid += 1\n",
    "            seq_array.append(seqs[id2index[line[sid1_index]]])\n",
    "        line[sid1_index] = id2_aid[line[sid1_index]]\n",
    "        if id2_aid.get(line[sid2_index]) is None:\n",
    "            id2_aid[line[sid2_index]] = sid\n",
    "            sid += 1\n",
    "            seq_array.append(seqs[id2index[line[sid2_index]]])\n",
    "        line[sid2_index] = id2_aid[line[sid2_index]]\n",
    "        raw_data.append(line)\n",
    "        if limit_data:\n",
    "            count += 1\n",
    "            if count >= max_data:\n",
    "                break\n",
    "    \n",
    "    # Extract index of 1st and 2nd sequences in pairs\n",
    "    seq_index1 = np.array([line[sid1_index] for line in tqdm(raw_data)])\n",
    "    seq_index2 = np.array([line[sid2_index] for line in tqdm(raw_data)])\n",
    "    \n",
    "\n",
    "    # Assign labels for pairs of sequences\n",
    "    class_map = {'0': 1, '1': 0}\n",
    "    class_labels = np.zeros((len(raw_data), 2))\n",
    "    for i in range(len(raw_data)):\n",
    "        class_labels[i][class_map[raw_data[i][label_index]]] = 1\n",
    "    \n",
    "    # Pretrained embed\n",
    "    if e_type == \"bepler\":\n",
    "        embedder = BeplerEmbedder()\n",
    "    elif e_type == \"prottrans_t5u50\":\n",
    "        embedder = ProtTransT5XLU50Embedder()\n",
    "    elif e_type == \"esm-1b\":\n",
    "        embedder = ESM1bEmbedder()\n",
    "        \n",
    "        \n",
    "    sequences = pd.read_csv(id2seq_file, sep=\"\\t\", header=None)\n",
    "    sequences = sequences.iloc[:,1].to_list()\n",
    "        \n",
    "    embeddings = []\n",
    "    i = 1\n",
    "    for sequence in sequences:\n",
    "        embeddings.append(embedder.embed(sequence))\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        i+=1\n",
    "        \n",
    "    embeddings = list(embeddings)\n",
    "    \n",
    "    seq_tensor= tf.keras.preprocessing.sequence.pad_sequences(embeddings,  padding='post', \n",
    "                                                              dtype='float16', truncating='post', maxlen=seq_max(id2seq_file))\n",
    "    dim = seq_tensor.shape[2]\n",
    "    \n",
    "\n",
    "    Path('preprocess').mkdir(parents=True, exist_ok=True)\n",
    "    np.savez('preprocess/embed_preprocess_' + e_type + '.npz', \n",
    "                 seq_tensor = seq_tensor, seq_index1 = seq_index1, \n",
    "                 seq_index2 = seq_index2, class_labels = class_labels, dim = dim)\n",
    "    \n",
    "    return seq_tensor, seq_index1, seq_index2, class_labels, dim\n",
    "        \n",
    "def leaky_relu(x, alpha = .3):\n",
    "    return tf.keras.backend.maximum(alpha*x, x)\n",
    "\n",
    "def build_model(hparams):\n",
    "    # Input of sequence tensor representations \n",
    "\n",
    "    seq_input1 = Input(shape=(seq_size, dim), name='seq1')\n",
    "    seq_input2 = Input(shape=(seq_size, dim), name='seq2')\n",
    "\n",
    "    # Define Conv1D and Bi-RNN (GRU/LSTM) use in architecture\n",
    "    l1=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r1=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l2=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r2=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l3=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r3=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l4=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r4=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l5=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "    r5=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
    "    l6=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
    "\n",
    "    # Siamese architecture\n",
    "\n",
    "    ### 1st sibling\n",
    "\n",
    "    # 1st Block RCNN \n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l1(seq_input1))\n",
    "    s1=concatenate([r1(s1), s1])\n",
    "\n",
    "    # 2nd Block RCNN\n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l2(s1))\n",
    "    s1=concatenate([r2(s1), s1])\n",
    "\n",
    "    # 3rd Block RCNN\n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l3(s1))\n",
    "    s1=concatenate([r3(s1), s1])\n",
    "\n",
    "    # 4th Block RCNN \n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l4(s1))\n",
    "    s1=concatenate([r4(s1), s1])\n",
    "\n",
    "    # 5th Block RCNN\n",
    "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l5(s1))\n",
    "    s1=concatenate([r5(s1), s1])\n",
    "\n",
    "    # Last convolution\n",
    "    s1=l6(s1)\n",
    "    s1=GlobalAveragePooling1D()(s1)\n",
    "\n",
    "    ### 2nd sibling\n",
    "\n",
    "    # 1st block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l1(seq_input2))\n",
    "    s2=concatenate([r1(s2), s2])\n",
    "\n",
    "    # 2nd block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l2(s2))\n",
    "    s2=concatenate([r2(s2), s2])\n",
    "\n",
    "    # 3rd block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l3(s2))\n",
    "    s2=concatenate([r3(s2), s2])\n",
    "\n",
    "    # 4th block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l4(s2))\n",
    "    s2=concatenate([r4(s2), s2])\n",
    "\n",
    "    # 5th block RCNN\n",
    "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l5(s2))\n",
    "    s2=concatenate([r5(s2), s2])\n",
    "\n",
    "    # Last convolution\n",
    "    s2=l6(s2)\n",
    "    s2=GlobalAveragePooling1D()(s2)\n",
    "\n",
    "    ### Combine two siblings of siamese architecture\n",
    "    merge_text = multiply([s1, s2])\n",
    "\n",
    "\n",
    "    #### MLP Part\n",
    "    # Set initializer\n",
    "\n",
    "    # First dense\n",
    "    x = Dense(hparams[HP_FIRST_DENSE], activation=hparams[HP_ACTIVATION])(merge_text)\n",
    "    # x = tf.keras.layers.LeakyReLU(alpha=.3)(x)\n",
    "    x = Dropout(hparams[HP_DROPOUT])(x)\n",
    "\n",
    "    # Second dense\n",
    "    x = Dense(int((hparams[HP_CONV_HIDDEN_DIM]+7)/2), activation=hparams[HP_ACTIVATION])(x)\n",
    "    # x = tf.keras.layers.LeakyReLU(alpha=.3)(x)\n",
    "    x = Dropout(hparams[HP_DROPOUT])(x)\n",
    "\n",
    "    # Last softmax\n",
    "    main_output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Combine to form functional model\n",
    "    merge_model = Model(inputs=[seq_input1, seq_input2], outputs=[main_output])\n",
    "    return merge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjvCG7HCp0Af",
    "outputId": "1dc8ea23-ae15-4c5b-ac61-ebd1a32b1b9e"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Optimisation Flags - Do not remove\n",
    "# ============================================\n",
    "\n",
    "# Disables caching (when set to 1) or enables caching (when set to 0) for just-in-time-compilation. When disabled,\n",
    "# no binary code is added to or retrieved from the cache.\n",
    "os.environ['CUDA_CACHE_DISABLE'] = '0' # orig is 0\n",
    "\n",
    "# When set to 1, forces the device driver to ignore any binary code embedded in an application \n",
    "# (see Application Compatibility) and to just-in-time compile embedded PTX code instead.\n",
    "# If a kernel does not have embedded PTX code, it will fail to load. This environment variable can be used to\n",
    "# validate that PTX code is embedded in an application and that its just-in-time compilation works as expected to guarantee application \n",
    "# forward compatibility with future architectures.\n",
    "os.environ['CUDA_FORCE_PTX_JIT'] = '1'# no orig\n",
    "os.environ['HOROVOD_GPU_ALLREDUCE'] = 'NCCL'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT']='1'\n",
    "os.environ['TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT'] = '1'\n",
    "os.environ['TF_ADJUST_HUE_FUSED'] = '1'\n",
    "os.environ['TF_ADJUST_SATURATION_FUSED'] = '1'\n",
    "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "os.environ['TF_SYNC_ON_FINISH'] = '0'\n",
    "os.environ['TF_AUTOTUNE_THRESHOLD'] = '2'\n",
    "os.environ['TF_DISABLE_NVTX_RANGES'] = '1'\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE\"] = \"1\"\n",
    "# =================================================\n",
    "# mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wmbio/WORK/gitworking/PIPR'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TGt47faMW5U6"
   },
   "outputs": [],
   "source": [
    "# Default hyperparameters\n",
    "CONV_HIDDEN_DIM = 50\n",
    "RNN_HIDDEN = 50\n",
    "N_EPOCHS = 30\n",
    "HIDDEN_DIM=50\n",
    "BATCH_SIZE = 32\n",
    "DTYPE='float16'\n",
    "LEARNING_RATE=.001\n",
    "EPSILON=1e-6\n",
    "MAX_DATASET_SIZE = 11187\n",
    "DATASET_SIZE = MAX_DATASET_SIZE\n",
    "KERNEL_SIZE = 3\n",
    "POOLING_KERNEL = 3\n",
    "EMBEDDING_TYPE = 'bepler' #bepler, prottrans_t5u50, esm-1b\n",
    "\n",
    "\n",
    "adam = Adam(learning_rate=LEARNING_RATE, amsgrad=True, epsilon=EPSILON)\n",
    "get_custom_objects().update({'leaky_relu': leaky_relu})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KgZZ2JvoBLw"
   },
   "source": [
    "### Protein EMBEDDING using pLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('preprocess/embed_preprocess_' + EMBEDDING_TYPE +'.npz'):\n",
    "    with np.load('preprocess/embed_preprocess_' + EMBEDDING_TYPE + '.npz') as data:\n",
    "        seq_tensor, seq_index1, seq_index2, class_labels, dim = data['seq_tensor'], data['seq_index1'], data['seq_index2'], data['class_labels'], data['dim']\n",
    "else :\n",
    "    seq_tensor, seq_index1, seq_index2, class_labels, dim = preprocess_embed(id2seq_file='data/wmbio_set/Train_set/human_custom_seq.tsv',\n",
    "                                                        ds_file='data/wmbio_set/Train_set/human_custom_ppi_pair.tsv',\n",
    "                                                        e_type=EMBEDDING_TYPE)\n",
    "\n",
    "# max sequence length\n",
    "seq_size = seq_max('data/wmbio_set/Train_set/human_custom_seq.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G34oBACWLqbw"
   },
   "source": [
    "### Define callbacks for monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQdf1RAsYVcA"
   },
   "outputs": [],
   "source": [
    "### Learning rate schedule for optimization during training\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.4,\n",
    "    patience=4,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_lr=1e-5)\n",
    "\n",
    "# Schedule early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=6,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "final_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.4,\n",
    "    patience=4,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_lr=1e-5)\n",
    "\n",
    "final_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', \n",
    "    verbose=1,\n",
    "    patience=7,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLqkyCvrruF-"
   },
   "source": [
    "### Define performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Um2gRMVrZPi",
    "outputId": "96eda6e8-15af-44a5-caa7-c2adea7d4fbf"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2, name='mcc'),\n",
    "      tfa.metrics.F1Score(num_classes=2, threshold=0.5, name='f1-score'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkG4si5QSf15"
   },
   "source": [
    "### Summary of model architecture - default parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0wMXJo9lqd6l",
    "outputId": "5ff95490-9d89-4b87-cc45-70b24481e945",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HP_EPSILON = hp.HParam('epsilon', hp.Discrete([1e-6]))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-3]))\n",
    "HP_FIRST_DENSE = hp.HParam('first_dense', hp.Discrete([100]))\n",
    "HP_KERNEL_SIZE = hp.HParam('kernel_size', hp.Discrete([3]))\n",
    "HP_POOLING_KERNEL = hp.HParam('pooling_kernel', hp.Discrete([3]))\n",
    "HP_CONV_HIDDEN_DIM = hp.HParam('conv_hidden_dim', hp.Discrete([50]))\n",
    "HP_RNN_HIDDEN_DIM = hp.HParam('rnn_hidden_dim', hp.Discrete([50]))\n",
    "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['leaky_relu']))\n",
    "HP_ACTIVATION_CONV = hp.HParam('activation_conv', hp.Discrete(['linear']))\n",
    "HP_REGULARIZER = hp.HParam('regularizer', hp.Discrete([0]))\n",
    "HP_CONV_PADDING = hp.HParam('conv_padding', hp.Discrete(['valid']))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0e-1]))\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([256]))\n",
    "HP_LEAKY_RELU = hp.HParam('leaky_relu', hp.Discrete([3e-1]))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "hparams = {\n",
    "  HP_EPSILON: EPSILON,\n",
    "  HP_LEARNING_RATE: LEARNING_RATE,\n",
    "  HP_FIRST_DENSE: 100,\n",
    "  HP_KERNEL_SIZE: 3,\n",
    "  HP_POOLING_KERNEL: 3,\n",
    "  HP_CONV_HIDDEN_DIM: 50,\n",
    "  HP_RNN_HIDDEN_DIM: 50,\n",
    "  HP_ACTIVATION: 'leaky_relu',\n",
    "  HP_ACTIVATION_CONV: 'relu',\n",
    "  HP_REGULARIZER: 0,\n",
    "  HP_CONV_PADDING: 'valid',\n",
    "  HP_DROPOUT: 3e-1,\n",
    "  HP_BATCH_SIZE: 256,\n",
    "  HP_LEAKY_RELU: 3e-1\n",
    "}\n",
    "\n",
    "model = build_model(hparams)\n",
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ONZlF6POBUX",
    "tags": []
   },
   "source": [
    "### Loop over all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b9czlGzdOR4",
    "outputId": "3c95c5fd-679e-42cb-abef-10769257e1bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=5, test_size=2, random_state=331)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cnt = 0\n",
    "\n",
    "# save hparams\n",
    "SAVE_MODEL = 'save_model_pretrained_' + EMBEDDING_TYPE\n",
    "Path(SAVE_MODEL).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for train, test in kf.split(class_labels):\n",
    "    cnt+=1\n",
    "    merge_model = None\n",
    "    with tf.device('/cpu:0'): # GPU mode일 경우, remove\n",
    "        merge_model = build_model(hparams)  \n",
    "        tf.keras.utils.plot_model(merge_model, to_file=SAVE_MODEL + 'model.png', show_shapes=True)\n",
    "\n",
    "\n",
    "        merge_model.compile(optimizer=Adam(learning_rate=hparams[HP_LEARNING_RATE], amsgrad=True, epsilon=hparams[HP_EPSILON]), \n",
    "                          loss='categorical_crossentropy', metrics=METRICS)\n",
    "\n",
    "        # Create train\n",
    "        # from generator\n",
    "        train_dataset = tf.data.Dataset.from_generator(generator_pair, \n",
    "                                                       args=[seq_tensor, class_labels, train], \n",
    "                                                       output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), \n",
    "                                                       output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
    "        train_dataset = train_dataset.shuffle(1024).repeat(N_EPOCHS).batch(hparams[HP_BATCH_SIZE])\n",
    "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        # Create test\n",
    "        test_dataset = tf.data.Dataset.from_generator(generator_pair, args=[seq_tensor, class_labels, test], \n",
    "                                                      output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), \n",
    "                                                      output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
    "        test_dataset = test_dataset.batch(hparams[HP_BATCH_SIZE])\n",
    "\n",
    "        # Save the best model base on val_accuracy\n",
    "        checkpoint = ModelCheckpoint(filepath=SAVE_MODEL + str(cnt)+'-fold_best_model.hdf5', \n",
    "                                     monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "        # Fit model\n",
    "        print(f'==================== Training time =====================')\n",
    "        history_model = merge_model.fit(train_dataset, \n",
    "                                        epochs=N_EPOCHS, \n",
    "                                        steps_per_epoch=len(train) // 128, \n",
    "                                        validation_data=test_dataset,\n",
    "                                        callbacks=[checkpoint, reduce_lr, early_stopping,                                               \n",
    "                                                  tf.keras.callbacks.CSVLogger(SAVE_MODEL + 'history.csv')])\n",
    "    # file rename\n",
    "    shutil.move(SAVE_MODEL + 'history.csv', SAVE_MODEL + str(cnt) + '-fold_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_model = None\n",
    "merge_model = build_model(hparams)  \n",
    "\n",
    "# ADAM\n",
    "merge_model.compile(optimizer=Adam(learning_rate=hparams[HP_LEARNING_RATE], \n",
    "                                   amsgrad=True, epsilon=hparams[HP_EPSILON]), \n",
    "                    loss='categorical_crossentropy', metrics=METRICS)\n",
    "\n",
    "# Create train\n",
    "train_dataset = tf.data.Dataset.from_generator(generator_pair, \n",
    "                                               args=[seq_tensor, class_labels, train], \n",
    "                                               output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), \n",
    "                                               output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
    "train_dataset = train_dataset.shuffle(1024).repeat(N_EPOCHS).batch(hparams[HP_BATCH_SIZE])\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Fit model\n",
    "history = merge_model.fit(train_dataset, \n",
    "                epochs=N_EPOCHS,\n",
    "                steps_per_epoch=len(seq_tensor) // 128, \n",
    "                callbacks=[final_reduce_lr, final_early_stopping])\n",
    "\n",
    "# model save\n",
    "SAVE_MODEL = 'final_model/'\n",
    "Path(SAVE_MODEL).mkdir(parents=True, exist_ok=True)\n",
    "merge_model.save(SAVE_MODEL + 'PIPR_'+EMBEDDING_TYPE+'_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 18078.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 166440.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 295373.52it/s]\n"
     ]
    }
   ],
   "source": [
    "seq_tensor, seq_index1, seq_index2, class_labels, dim = preprocess_embed(id2seq_file='data/wmbio_set/Test_set/human_test_seq.tsv',\n",
    "                                                                         ds_file='data/wmbio_set/Test_set/human_test_pair.tsv',\n",
    "                                                                         e_type=EMBEDDING_TYPE,\n",
    "                                                                         predict=True) \n",
    "\n",
    "# max sequence length\n",
    "seq_size = seq_max('data/wmbio_set/Train_set/human_custom_seq.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('final_model/PIPR_befler_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82994366, 0.17005637],\n",
       "       [0.99306023, 0.00693977],\n",
       "       [0.81467044, 0.18532953],\n",
       "       [0.00521381, 0.99478614],\n",
       "       [0.9263858 , 0.07361418]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([seq_tensor[seq_index1], seq_tensor[seq_index2]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluation-Benchmark-dataset-baseline-PIPR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pipr",
   "language": "python",
   "name": "pipr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
